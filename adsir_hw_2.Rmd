---
title: "adsir_hw_2"
author: "Jake Greenberg"
date: "3/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) #warning = FALSE, message = FALSE)
```

```{r warning = FALSE, message = FALSE}
library(tidyverse) # for graphing and data cleaning
library(tidymodels) # for modeling
library(stacks) # for stacking models
library(naniar) # for examining missing values (NAs)
library(lubridate) # for data manipulation
library(moderndive) # for King Country housing data
library(vip) # for variable importance plots
library(DALEX) # for model interpretation
library(DALEXtra) # for extension of DALEX
library(patchwork) # for combining plots nicely

theme_set(theme_minimal()) # Lisa's favorite theme
```

# Would you actually have this variable to predict with at the time you are going to make the prediction
# Looking at removing variables with only one value (zero variance) (step_nzf should get rid of these observations)

```{r}
data("lending_club")
# Data dictionary (as close as I could find): https://www.kaggle.com/wordsforthewise/lending-club/discussion/170691
create_more_bad <- lending_club %>% 
  filter(Class == "bad") %>% 
  sample_n(size = 3000, replace = TRUE)

lending_club_mod <- lending_club %>% 
  bind_rows(create_more_bad)
```

```{r}
lending_club_mod %>% 
  group_by(term) %>% 
  summarize(n())
```

```{r}
lending_club_mod %>% 
  ggplot(aes(x = funded_amnt)) + geom_density()

lending_club_mod %>% 
  ggplot(aes(x = int_rate)) + geom_density()

lending_club_mod %>% 
  ggplot(aes(x = annual_inc)) + geom_density()

lending_club_mod %>% 
  ggplot(aes(x = total_bal_il)) + geom_density()

lending_club_mod %>% 
  group_by(class) %>% 
  summarize(n())

lending_club_mod %>% 
  group_by(term) %>% 
  summarize(n())

lending_club_mod %>% 
  group_by(addr_state) %>% 
  summarize(n())


lending_club_mod %>% 
  group_by(sub_grade) %>% 
  summarize(n())

summary(lending_club_mod)
```

```{r}
sum(is.na(lending_club_mod)) # counts the number of NA values for all variables
```

```{r}
# checks for duplicate observations
lending_club_mod %>% 
  distinct()
```

```{r}
set.seed(494)
lending_club_split <- initial_split(lending_club_mod, prop = .75, strata = Class)
lending_club_train <- training(lending_club_split)
lending_club_test <- testing(lending_club_split)
```

```{r}
unique(lending_club_train$verification_status)
```

```{r}
lending_club_recipe <- recipe(Class ~ ., data = lending_training) %>% 
  step_mutate_at(all_numeric(), fn = ~as.numeric(.)) %>% 
  step_mutate(verification_status = as.factor(ifelse(verification_status == "Source_Verified", "Verified", verification_status))) %>% 
  step_mutate(annual_inc = case_when(annual_inc <= 9875 ~ 10,
                                     annual_inc > 9875 && annual_inc <= 40125 ~ 12,
                                     annual_inc > 40125 && annual_inc <= 85526 ~ 22,
                                     annual_inc > 85526 && annual_inc <= 163300 ~ 24,
                                     annual_inc >163300 && annual_inc <= 207350 ~ 32,
                                     annual_inc > 207350 && annual_inc <= 518400 ~ 35,
                                     annual_inc > 518400 ~ 37)) %>% 
  step_mutate(annual_inc = as.factor(annual_inc)) %>% 
  step_rm(acc_now_delinq, delinq_amnt) %>% 
  step_normalize(all_predictors(),
                 -all_nominal()) %>% 
  step_dummy(all_nominal(),
             -all_outcomes())

lending_club_recipe %>% 
  prep(lending_club_train) %>% 
  juice()
```


Set up the lasso model and workflow. We will tune the penalty parameter.

```{r}
lending_club_lasso_mod <- 
  # Define a linear regression model
  logistic_reg(mixture = 1) %>% 
  # Set the engine to "lm" (lm() function is used to fit model)
  set_engine("glmnet") %>% 
  set_args(penalty = tune()) %>% 
  # Not necessary here, but good to remember for other models
  set_mode("classification")



lending_club_lasso_wf <- 
  # Set up the workflow
  workflow() %>% 
  # Add the recipe
  add_recipe(lending_club_recipe) %>% 
  # Add the modeling
  add_model(lending_club_lasso_mod)

lending_club_lasso_wf
```


```{r}
set.seed(494) #for reproducible 5-fold
lending_club_cv <- vfold_cv(lending_club_train, v = 5)

penalty_grid <- grid_regular(penalty(),
                             levels = 20)
control_grid <- control_stack_grid()

lending_club_lasso_tune <- lending_club_lasso_wf %>% 
  tune_grid(resamples = lending_club_cv,
            grid = penalty_grid,
            control= control_grid)
lending_club_lasso_tune
```


```{r}
lending_club_lasso_tune %>%
  show_best(metric = "accuracy")
```


```{r}
lending_lasso_tune %>% 
  collect_metrics() %>% 
  filter(.config == "Preprocessor1_Model13")
```

```{r}
set.seed(494) # for reproducibility
lending_club_cv <- vfold_cv(lending_club_train, v = 5)
```

```{r}
penalty_grid <- grid_regular(penalty(),
                             levels = 10)

# add ctrl_grid - assures predictions and workflows are saved
ctrl_grid <- control_stack_grid()

# tune the model using the same cv samples as random forest
metric <- metric_set(accuracy)

lending_club_lasso_tune <- 
  lending_club_lasso_wf %>% 
  tune_grid(
    resamples = lending_club_cv,
    grid = penalty_grid,
    metrics = metric,
    control = ctrl_grid
    )

lending_club_lasso_tune
```


```{r}
lending_club_lasso_tune %>% 
  collect_metrics() %>% 
  filter(.metric == "accuracy") %>% 
  ggplot(aes(x = penalty, y = mean)) +
  geom_point() +
  geom_line() +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10",scales::math_format(10^.x))) +
  labs(x = "penalty", y = "accuracy")
```


```{r}
hotels_lasso_tune %>% 
  show_best(metric = "accuracy")

best <- hotels_lasso_tune %>% 
  select_best(metric = "accuracy")
```


```{r}
hotels_lasso_final_wf <- hotels_lasso_wf %>% 
  finalize_workflow(best)

hotels_lasso_final_wf
```


```{r}
hotels_lasso_final_mod <- hotels_lasso_final_wf %>% 
  fit(data = hotels_train)

hotels_lasso_final_mod %>% 
  pull_workflow_fit() %>% 
  tidy() 
```


```{r}
ranger_spec <- 
  rand_forest(mtry = 6, 
              min_n = 10, 
              trees = 200) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")
```

Next, we create the workflow:

```{r}
ranger_workflow <- 
  workflow() %>% 
  add_recipe(lending_club_recipe) %>% 
  add_model(ranger_spec) 
```


And then we fit the model (be sure to have the ranger library installed first, although it doesnâ€™t need to be loaded):
```{r}
ranger_fit <- ranger_workflow %>% 
  fit(lending_club_train)

ranger_fit
```


Set up the model tuning for the penalty parameter. Be sure to add the control_stack_grid() for the control argument so we can use these results later when we stack. Find the accuracy and area under the roc curve for the model with the best tuning parameter. Use 5-fold cv.


